from pytrends.request import TrendReq
import pandas as pd
from datetime import datetime
import time

class FreeTrendAnalyzer:
    def __init__(self):
        """åˆå§‹åŒ–,æ·»åŠ æ›´ç¨³å®šçš„é…ç½®"""
        try:
            self.pytrend = TrendReq(
                hl='en-US',
                tz=360,
                timeout=(10, 25),
                retries=2,
                backoff_factor=0.1,
                requests_args={'verify': True}  # æ·»åŠ SSLéªŒè¯
            )
            print(" pytrends åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f" åˆå§‹åŒ–å¤±è´¥: {e}")
         
            raise
    
    def get_trend_data(self, keywords, timeframe='today 12-m', geo=''):
        """
        è·å–æœç´¢è¶‹åŠ¿æ•°æ®(å¸¦é”™è¯¯å¤„ç†)
        
        å‚æ•°:
        - keywords: åˆ—è¡¨,æœ€å¤š5ä¸ªå…³é”®è¯
        - timeframe: 'today 12-m', 'today 3-m', 'now 7-d' ç­‰
        - geo: åœ°åŒºä»£ç  (''=å…¨çƒ, 'US'=ç¾å›½, 'CN'=ä¸­å›½)
        """
        try:
            # é™åˆ¶å…³é”®è¯æ•°é‡
            if len(keywords) > 5:
                print(f"âš ï¸ å…³é”®è¯è¿‡å¤š({len(keywords)}),åªå–å‰5ä¸ª")
                keywords = keywords[:5]
            
            print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢: {keywords}")
            
            self.pytrend.build_payload(
                kw_list=keywords,
                cat=0,
                timeframe=timeframe,
                geo=geo,
                gprop=''
            )
            
            # è·å–æ•°æ®
            interest_over_time = self.pytrend.interest_over_time()
            
            if interest_over_time.empty:
                print("âš ï¸ æœªæ‰¾åˆ°æ•°æ®(å¯èƒ½å…³é”®è¯æœç´¢é‡å¤ªä½)")
                return pd.DataFrame()
            
            # ç§»é™¤ 'isPartial' åˆ—
            if 'isPartial' in interest_over_time.columns:
                interest_over_time = interest_over_time.drop('isPartial', axis=1)
            
            print(f"âœ… æˆåŠŸè·å– {len(interest_over_time)} æ¡æ•°æ®")
            return interest_over_time
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_related_queries(self, keyword):
        """è·å–ç›¸å…³æœç´¢æŸ¥è¯¢"""
        try:
            self.pytrend.build_payload([keyword], timeframe='today 12-m')
            related = self.pytrend.related_queries()
            
            return {
                'rising': related[keyword]['rising'],
                'top': related[keyword]['top']
            }
        except Exception as e:
            print(f"âŒ è·å–ç›¸å…³æŸ¥è¯¢å¤±è´¥: {e}")
            return {'rising': None, 'top': None}
    
    def safe_analyze(self, keyword, delay=2):
        """
       
        å‚æ•°:
        - delay: è¯·æ±‚é—´éš”(ç§’)
        """
        results = {}
        
        # 1. è¶‹åŠ¿æ•°æ®
        print(f"\n{'='*60}")
        print(f"ğŸ“Š åˆ†æå…³é”®è¯: {keyword}")
        print(f"{'='*60}")
        
        trend_data = self.get_trend_data([keyword])
        if not trend_data.empty:
            results['avg_interest'] = trend_data[keyword].mean()
            results['max_interest'] = trend_data[keyword].max()
            results['current_trend'] = 'ğŸ“ˆ ä¸Šå‡' if trend_data[keyword].iloc[-1] > trend_data[keyword].iloc[0] else 'ğŸ“‰ ä¸‹é™'
            print(f"å¹³å‡çƒ­åº¦: {results['avg_interest']:.1f}")
            print(f"æœ€é«˜çƒ­åº¦: {results['max_interest']}")
            print(f"è¶‹åŠ¿æ–¹å‘: {results['current_trend']}")
        
        time.sleep(delay)  # å»¶è¿Ÿé¿å…å°ç¦
        
        # 2. ç›¸å…³æŸ¥è¯¢
        print(f"\nğŸ”— ç›¸å…³æŸ¥è¯¢...")
        related = self.get_related_queries(keyword)
        if related['rising'] is not None:
            results['rising_queries'] = related['rising']['query'].head(5).tolist()
            print("ä¸Šå‡æŸ¥è¯¢:")
            for q in results['rising_queries']:
                print(f"  â€¢ {q}")
        
        return results




def test_pytrends():
    """æµ‹è¯•ZBAAæ–‡ç« çš„10ä¸ªSEOå…³é”®è¯"""
    print("ğŸš€ å¼€å§‹åˆ†æZBAA SEOå…³é”®è¯è¶‹åŠ¿\n")
    
    try:
        analyzer = FreeTrendAnalyzer()
        
        # å®šä¹‰10ä¸ªå…³é”®è¯ï¼ˆæŒ‰ç­–ç•¥åˆ†ç»„ï¼‰
        primary_keywords = [
            "private jet charter Beijing",
            "business aviation Beijing",
            "private jet rental China"
        ]

        secondary_keywords = [
            "Beijing to Shanghai private jet",
            "Beijing Hong Kong charter flight",
            "executive jet China",
            "business jet charter Asia"
        ]

        longtail_keywords = [
            "how much private jet Beijing to Hong Kong",
            "best private jet for long distance flights",
            "VIP flight service Beijing airport"
        ]
        
        all_keywords = primary_keywords + secondary_keywords + longtail_keywords
        
        # å­˜å‚¨ç»“æœ
        results_summary = []
        
        print("="*80)
        print("ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»è¦å…³é”®è¯åˆ†æï¼ˆPrimary Keywordsï¼‰")
        print("="*80)
        
        for i, keyword in enumerate(primary_keywords, 1):
            print(f"\n[{i}/10] åˆ†æ: {keyword}")
            result = analyzer.safe_analyze(keyword, delay=3)
            if result:
                results_summary.append({
                    'keyword': keyword,
                    'type': 'Primary',
                    'avg_interest': result.get('avg_interest', 0),
                    'trend': result.get('current_trend', 'N/A')
                })
            time.sleep(3)
        
        print("\n" + "="*80)
        print("ç¬¬äºŒéƒ¨åˆ†ï¼šæ¬¡è¦å…³é”®è¯åˆ†æï¼ˆSecondary Keywordsï¼‰")
        print("="*80)
        
        for i, keyword in enumerate(secondary_keywords, 4):
            print(f"\n[{i}/10] åˆ†æ: {keyword}")
            result = analyzer.safe_analyze(keyword, delay=3)
            if result:
                results_summary.append({
                    'keyword': keyword,
                    'type': 'Secondary',
                    'avg_interest': result.get('avg_interest', 0),
                    'trend': result.get('current_trend', 'N/A')
                })
            time.sleep(3)
        
        print("\n" + "="*80)
        print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šé•¿å°¾å…³é”®è¯åˆ†æï¼ˆLong-tail Keywordsï¼‰")
        print("="*80)
        
        for i, keyword in enumerate(longtail_keywords, 8):
            print(f"\n[{i}/10] åˆ†æ: {keyword}")
            result = analyzer.safe_analyze(keyword, delay=3)
            if result:
                results_summary.append({
                    'keyword': keyword,
                    'type': 'Long-tail',
                    'avg_interest': result.get('avg_interest', 0),
                    'trend': result.get('current_trend', 'N/A')
                })
            time.sleep(3)
        
        # ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š
        print("\n" + "="*80)
        print("ğŸ“Š å…³é”®è¯çƒ­åº¦å¯¹æ¯”æ€»ç»“")
        print("="*80)
        
        if results_summary:
            df_results = pd.DataFrame(results_summary)
            df_results = df_results.sort_values('avg_interest', ascending=False)
            
            print(f"\n{'æ’å':<5} {'å…³é”®è¯':<50} {'ç±»å‹':<12} {'å¹³å‡çƒ­åº¦':<10} {'è¶‹åŠ¿'}")
            print("-" * 90)
            
            for idx, row in df_results.iterrows():
                print(f"{df_results.index.get_loc(idx)+1:<5} {row['keyword']:<50} {row['type']:<12} {row['avg_interest']:<10.1f} {row['trend']}")
            
            # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
            print("\n" + "="*80)
            print("ğŸ“ˆ æŒ‰ç±»å‹åˆ†ç»„åˆ†æ")
            print("="*80)
            
            type_stats = df_results.groupby('type')['avg_interest'].agg(['mean', 'max', 'min'])
            print(f"\n{'å…³é”®è¯ç±»å‹':<15} {'å¹³å‡çƒ­åº¦':<12} {'æœ€é«˜çƒ­åº¦':<12} {'æœ€ä½çƒ­åº¦'}")
            print("-" * 55)
            for kw_type, stats in type_stats.iterrows():
                print(f"{kw_type:<15} {stats['mean']:<12.1f} {stats['max']:<12.1f} {stats['min']:<12.1f}")
        
        # é¢å¤–æµ‹è¯•ï¼šå¯¹æ¯”æ ¸å¿ƒå…³é”®è¯ç»„ï¼ˆGoogle Trendsé™åˆ¶5ä¸ªï¼‰
        print("\n" + "="*80)
        print("ğŸ”¥ æ ¸å¿ƒå…³é”®è¯ç›´æ¥å¯¹æ¯”ï¼ˆTop 5ï¼‰")
        print("="*80)
        
        top_5_keywords = [
            "private jet charter Beijing",
            "business aviation Beijing",
            "ultra long range jets",
            "VIP terminal Beijing",
            "Beijing Hong Kong private jet"
        ]
        
        comparison = analyzer.get_trend_data(top_5_keywords, timeframe='today 12-m')
        
        if not comparison.empty:
            print("\nè¿‡å»12ä¸ªæœˆå¹³å‡çƒ­åº¦å¯¹æ¯”:")
            for kw in top_5_keywords:
                if kw in comparison.columns:
                    avg = comparison[kw].mean()
                    trend = 'ğŸ“ˆ' if comparison[kw].iloc[-1] > comparison[kw].iloc[0] else 'ğŸ“‰'
                    print(f"  {trend} {kw:<40} {avg:.1f}")
        
        print("\nğŸ‰ åˆ†æå®Œæˆ! å»ºè®®æ ¹æ®çƒ­åº¦æ•°æ®è°ƒæ•´å…³é”®è¯ä¼˜å…ˆçº§")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_pytrends()